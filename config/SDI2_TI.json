{
    "output_dir": "",
    "cache_dir": "pretrained",
    "pretrained_model_name_or_path": "stabilityai/stable-diffusion-2-inpainting",
    "memory_saving": 0,

    "normal_words": "a person",
    "personalized_words": "a <person>",

    "_text_in_all": ["ID", "CLIP-S", "Token", "None"],
    "text_in": "Token",

    "_text_out_all": ["ID", "CLIP-A", "None"],
    "text_out": "None",

    "loss": {
        "ID": 0,
        "DSM": 1.0
    },

    "data": {
        "resolution": 512,
        "data_dir": "data/celebahq"
    },

    "optimizer": {
        "lr": 1e-5,
        "weight_decay": 0.01
    },

    "training": {
        "batch_size": 1,
        "num_time_resample": 4,
        "gradient_accumulation_steps": 8,
        "max_train_steps": 5000,
        "output_dir": "expr/celebahq/SDI2_TI"
    },

    "sampling": {
        "_all_modules": ["dpmsolver", "ddim"],
        "sampler": "ddim"
    },

    "modifier_token": {
        "init_token": "person",
        "name": "<person>",
        "mode": "single_token",
        "num_tokens": 1,
        "lr": 2e-2
    },

    "id_trans_net": {
        "arch": {
            "in_dim": 512,
            "out_dim": 1024,
            "num_layer": 4,
            "num_q_token": 10
        },
        "training": {
            "lr": 1.6e-5
        }
    },

    "clip_image_enc": {
        "_tune_params_all": ["QKV", "KV", "All", "None", "Proj"],
        "tune_params": "None"
    },

    "unet": {
        "_tune_params_all": ["PVA", "QKV", "CrossQKV", "KV", "All", "None"],
        "attention": "QKV",
        "tune_params": "None"
    },

    "face_net": {
        "_tune_params_all": ["All", "None"],
        "tune_params": "None"
    }
}
